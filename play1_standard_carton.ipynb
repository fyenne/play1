{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dscshap3808\\\\Documents\\\\my_scripts_new\\\\play1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster\n",
    "import os\n",
    "import re\n",
    "# import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ou_code</th>\n",
       "      <th>operation_day</th>\n",
       "      <th>inbound_receive_qty</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>outbound_shipped_qty</th>\n",
       "      <th>total_head_count</th>\n",
       "      <th>total_working_hour</th>\n",
       "      <th>outsource_working_hour</th>\n",
       "      <th>perm_working_hour</th>\n",
       "      <th>other_working_hour</th>\n",
       "      <th>direct_working_hour</th>\n",
       "      <th>indirect_working_hour</th>\n",
       "      <th>outbound_inbound_qty_ratio</th>\n",
       "      <th>perm_working_hour_ratio</th>\n",
       "      <th>working_hour_per_head</th>\n",
       "      <th>location_usage_rate</th>\n",
       "      <th>location_idle_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CN-001</td>\n",
       "      <td>20210430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.1875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN-001</td>\n",
       "      <td>20210619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.988372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN-001</td>\n",
       "      <td>20210427</td>\n",
       "      <td>4794.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.541927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN-001</td>\n",
       "      <td>20210419</td>\n",
       "      <td>11400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CN-001</td>\n",
       "      <td>20210617</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13527.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.657895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.1160</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.998400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ou_code  operation_day  inbound_receive_qty  is_holiday  \\\n",
       "0  CN-001       20210430                  0.0           0   \n",
       "1  CN-001       20210619                  0.0           1   \n",
       "2  CN-001       20210427               4794.0           0   \n",
       "3  CN-001       20210419              11400.0           0   \n",
       "4  CN-001       20210617                114.0           0   \n",
       "\n",
       "   outbound_shipped_qty  total_head_count  total_working_hour  \\\n",
       "0                1699.0               4.0               32.75   \n",
       "1                   0.0               3.0               30.00   \n",
       "2                7392.0               4.0               32.28   \n",
       "3                6000.0               4.0               33.25   \n",
       "4               13527.0               5.0               40.58   \n",
       "\n",
       "   outsource_working_hour  perm_working_hour  other_working_hour  \\\n",
       "0                     0.0               0.00                 0.0   \n",
       "1                     0.0              30.00                 0.0   \n",
       "2                     0.0               0.00                 0.0   \n",
       "3                     0.0               0.00                 0.0   \n",
       "4                     0.0              40.58                 0.0   \n",
       "\n",
       "   direct_working_hour  indirect_working_hour  outbound_inbound_qty_ratio  \\\n",
       "0                32.75                    0.0                    0.000000   \n",
       "1                30.00                    0.0                    0.000000   \n",
       "2                32.28                    0.0                    1.541927   \n",
       "3                33.25                    0.0                    0.526316   \n",
       "4                40.58                    0.0                  118.657895   \n",
       "\n",
       "   perm_working_hour_ratio  working_hour_per_head  location_usage_rate  \\\n",
       "0                      0.0                 8.1875             0.000000   \n",
       "1                      1.0                10.0000             0.011628   \n",
       "2                      0.0                 8.0700             0.000000   \n",
       "3                      0.0                 8.3125             0.000000   \n",
       "4                      1.0                 8.1160             0.001600   \n",
       "\n",
       "   location_idle_rate  \n",
       "0            0.000000  \n",
       "1            0.988372  \n",
       "2            0.000000  \n",
       "3            0.000000  \n",
       "4            0.998400  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./daily_ou_kpi.csv') \n",
    "re1 = re.compile(r'(?<=\\.).+')\n",
    "df.columns = [re1.findall(i)[0] for i in list(df.columns.to_numpy())]\n",
    "# df.to_csv('./daily_kpi_all_810.csv', encoding='utf_8_sig')\n",
    "\n",
    "clean_df1 = (df.groupby('ou_code')['operation_day'].count() <2).reset_index()\n",
    "clean_df1.columns = ['ou_code', 'flag1']\n",
    "df = clean_df1.merge(df, on = 'ou_code', how = 'inner')\n",
    "df = df[df['flag1'] == False]\n",
    "\n",
    "clean_df2 = df.groupby('ou_code')[[\n",
    "    'inbound_receive_qty', 'outbound_shipped_qty'\n",
    "    ]].sum().reset_index()\n",
    "clean_df2['sum'] = clean_df2.sum(axis = 1)\n",
    "clean_df2 = clean_df2[clean_df2['sum'] != 0]\n",
    "df = df[df['ou_code'].isin(clean_df2.ou_code)]\n",
    "\n",
    "clean_df3 = (df.groupby('ou_code')[[\n",
    "    'total_working_hour'\n",
    "    ]].sum() == 0).reset_index()\n",
    "clean_df3 = clean_df3[clean_df3['total_working_hour'] == False]\n",
    "# clean_df4 = (df.groupby('ou_code')[[\n",
    "#     'outsource_working_hour'\n",
    "#     ]].sum() == 0).reset_index()\n",
    "# clean_df4 = clean_df4[clean_df4['outsource_working_hour'] == False]\n",
    "# df = df[df['ou_code'].isin(clean_df4.ou_code)]\n",
    "# df= df.reset_index()\n",
    " \n",
    "# df = df[df['ou_code'].isin(clean_df3.ou_code)]\n",
    "# df= df.reset_index()\n",
    "\n",
    "df = df[[\n",
    "    'ou_code','operation_day', 'inbound_receive_qty', 'is_holiday',\n",
    "    'outbound_shipped_qty','total_head_count','total_working_hour',\n",
    "    'outsource_working_hour', 'perm_working_hour',\n",
    "    'other_working_hour', 'direct_working_hour', 'indirect_working_hour',\n",
    "    'outbound_inbound_qty_ratio', 'perm_working_hour_ratio',\n",
    "    'working_hour_per_head', 'location_usage_rate', 'location_idle_rate']]\n",
    "df = df.fillna(0)\n",
    "df = df[df['total_working_hour'] != 0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "res = smf.ols(\n",
    "    'total_working_hour ~ inbound_receive_qty + outbound_shipped_qty', \n",
    "    data=df).fit()\n",
    "res.summary()\n",
    "\n",
    "df['operation_day'] = pd.to_datetime(df['operation_day'].apply(str), yearfirst = True)\n",
    "df.set_index(['ou_code', 'operation_day'], inplace=True)\n",
    "df['ou_codes'] = df.index.get_level_values(0)  \n",
    "\n",
    "from linearmodels import PanelOLS\n",
    "# Regression\n",
    "FE = PanelOLS(df['total_working_hour'], df[['inbound_receive_qty','outbound_shipped_qty']],\n",
    "            entity_effects = True,\n",
    "            time_effects = True,\n",
    "            check_rank =True,\n",
    "              )\n",
    "            \n",
    "# Result\n",
    "result = FE.fit(\n",
    "  cov_type = 'clustered',\\\n",
    "  cluster_entity=True,\n",
    "  cluster_time=True\n",
    "            )\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dkrei predicitoonS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>inbound_receive_qty</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>outbound_shipped_qty</th>\n",
       "      <th>total_head_count</th>\n",
       "      <th>total_working_hour</th>\n",
       "      <th>outsource_working_hour</th>\n",
       "      <th>perm_working_hour</th>\n",
       "      <th>other_working_hour</th>\n",
       "      <th>direct_working_hour</th>\n",
       "      <th>indirect_working_hour</th>\n",
       "      <th>outbound_inbound_qty_ratio</th>\n",
       "      <th>perm_working_hour_ratio</th>\n",
       "      <th>working_hour_per_head</th>\n",
       "      <th>location_usage_rate</th>\n",
       "      <th>location_idle_rate</th>\n",
       "      <th>ou_codes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ou_code</th>\n",
       "      <th>operation_day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">CN-001</th>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.1875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CN-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>CN-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-27</th>\n",
       "      <td>4794.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.541927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CN-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-19</th>\n",
       "      <td>11400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CN-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-17</th>\n",
       "      <td>114.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13527.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.657895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.1160</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>CN-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-15</th>\n",
       "      <td>17922.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CN-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0340</td>\n",
       "      <td>0.122146</td>\n",
       "      <td>0.877854</td>\n",
       "      <td>CN-001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       inbound_receive_qty  is_holiday  outbound_shipped_qty  \\\n",
       "ou_code operation_day                                                          \n",
       "CN-001  2021-04-30                     0.0           0                1699.0   \n",
       "        2021-06-19                     0.0           1                   0.0   \n",
       "        2021-04-27                  4794.0           0                7392.0   \n",
       "        2021-04-19                 11400.0           0                6000.0   \n",
       "        2021-06-17                   114.0           0               13527.0   \n",
       "        2021-04-15                 17922.0           0                1591.0   \n",
       "        2021-07-21                     0.0           0                1542.0   \n",
       "\n",
       "                       total_head_count  total_working_hour  \\\n",
       "ou_code operation_day                                         \n",
       "CN-001  2021-04-30                  4.0               32.75   \n",
       "        2021-06-19                  3.0               30.00   \n",
       "        2021-04-27                  4.0               32.28   \n",
       "        2021-04-19                  4.0               33.25   \n",
       "        2021-06-17                  5.0               40.58   \n",
       "        2021-04-15                  4.0               34.75   \n",
       "        2021-07-21                  5.0               45.17   \n",
       "\n",
       "                       outsource_working_hour  perm_working_hour  \\\n",
       "ou_code operation_day                                              \n",
       "CN-001  2021-04-30                        0.0               0.00   \n",
       "        2021-06-19                        0.0              30.00   \n",
       "        2021-04-27                        0.0               0.00   \n",
       "        2021-04-19                        0.0               0.00   \n",
       "        2021-06-17                        0.0              40.58   \n",
       "        2021-04-15                        0.0               0.00   \n",
       "        2021-07-21                        0.0              45.17   \n",
       "\n",
       "                       other_working_hour  direct_working_hour  \\\n",
       "ou_code operation_day                                            \n",
       "CN-001  2021-04-30                    0.0                32.75   \n",
       "        2021-06-19                    0.0                30.00   \n",
       "        2021-04-27                    0.0                32.28   \n",
       "        2021-04-19                    0.0                33.25   \n",
       "        2021-06-17                    0.0                40.58   \n",
       "        2021-04-15                    0.0                34.75   \n",
       "        2021-07-21                    0.0                45.17   \n",
       "\n",
       "                       indirect_working_hour  outbound_inbound_qty_ratio  \\\n",
       "ou_code operation_day                                                      \n",
       "CN-001  2021-04-30                       0.0                    0.000000   \n",
       "        2021-06-19                       0.0                    0.000000   \n",
       "        2021-04-27                       0.0                    1.541927   \n",
       "        2021-04-19                       0.0                    0.526316   \n",
       "        2021-06-17                       0.0                  118.657895   \n",
       "        2021-04-15                       0.0                    0.088774   \n",
       "        2021-07-21                       0.0                    0.000000   \n",
       "\n",
       "                       perm_working_hour_ratio  working_hour_per_head  \\\n",
       "ou_code operation_day                                                   \n",
       "CN-001  2021-04-30                         0.0                 8.1875   \n",
       "        2021-06-19                         1.0                10.0000   \n",
       "        2021-04-27                         0.0                 8.0700   \n",
       "        2021-04-19                         0.0                 8.3125   \n",
       "        2021-06-17                         1.0                 8.1160   \n",
       "        2021-04-15                         0.0                 8.6875   \n",
       "        2021-07-21                         1.0                 9.0340   \n",
       "\n",
       "                       location_usage_rate  location_idle_rate ou_codes  \n",
       "ou_code operation_day                                                    \n",
       "CN-001  2021-04-30                0.000000            0.000000   CN-001  \n",
       "        2021-06-19                0.011628            0.988372   CN-001  \n",
       "        2021-04-27                0.000000            0.000000   CN-001  \n",
       "        2021-04-19                0.000000            0.000000   CN-001  \n",
       "        2021-06-17                0.001600            0.998400   CN-001  \n",
       "        2021-04-15                0.000000            0.000000   CN-001  \n",
       "        2021-07-21                0.122146            0.877854   CN-001  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = df.copy();data_all.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "train, test  = train_test_split(data_all, \\\n",
    "    test_size=0.20, random_state=42, stratify = data_all['ou_codes'])\n",
    "train, valid = train_test_split(train, \\\n",
    "    test_size=0.20, random_state=42, stratify = train['ou_codes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_dummie(df):\n",
    "    df = pd.concat([df.drop('ou_codes', axis =1) , pd.get_dummies(df['ou_codes'])], axis =1)\n",
    "    return df\n",
    "train, valid, test = [go_dummie(i) for i in [train, valid, test]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.pop('total_working_hour')\n",
    "valid_y = valid.pop('total_working_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time #implementing in this function the time spent on training the model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "def modelfit(alg, dtrain, target, only_predict = False):\n",
    "    #Fit the algorithm on the data\n",
    "    time_start = time.perf_counter() #start counting the time\n",
    "    if not only_predict:\n",
    "        alg.fit(dtrain, target)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "    \n",
    "    kfolds = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_score = cross_val_score(alg, dtrain,target, cv=kfolds, scoring='neg_mean_squared_error')\n",
    "    cv_score = np.sqrt(-cv_score)\n",
    "    \n",
    "    time_end = time.perf_counter()\n",
    "    \n",
    "    total_time = time_end-time_start\n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"RMSE :  {:.4f}\".format(np.sqrt(mean_squared_error(target, dtrain_predictions))))\n",
    "    print(\"CV Score : Mean -  %.4f | Std -  %.4f | Min -  %.4f | Max - %.4f\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "    print(\"Amount of time spent during training the model and cross validation: %4.3f seconds\" % (total_time))\n",
    "    \n",
    "def plot_feature_importance(model, df):\n",
    "    feature_importance = model.feature_importances_[:30]\n",
    "    # make importances relative to max importance\n",
    "    plt.figure(figsize=(20, 20)) #figure size\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max()) #making it a percentage relative to the max value\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    plt.yticks(pos, df.columns[sorted_idx], fontsize=15) #used train_drop here to show the name of each feature instead of our train_prepared \n",
    "    plt.xlabel('Relative Importance', fontsize=20)\n",
    "    plt.ylabel('Features', fontsize=20)\n",
    "    plt.title('Variable Importance', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "RMSE :  0.0000\n",
      "CV Score : Mean -  0.0000 | Std -  0.0000 | Min -  0.0000 | Max - 0.0000\n",
      "Amount of time spent during training the model and cross validation: 0.313 seconds\n"
     ]
    }
   ],
   "source": [
    "lin_reg = Ridge()\n",
    "modelfit(lin_reg, train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "RMSE :  0.0181\n",
      "CV Score : Mean -  0.0178 | Std -  0.0024 | Min -  0.0146 | Max - 0.0206\n",
      "Amount of time spent during training the model and cross validation: 2.153 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "rid_reg = Lasso()\n",
    "modelfit(rid_reg, train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "RMSE :  4.6620\n",
      "CV Score : Mean -  6.1535 | Std -  1.9010 | Min -  4.3007 | Max - 10.0638\n",
      "Amount of time spent during training the model and cross validation: 61.108 seconds\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest_reg = RandomForestRegressor(n_estimators=300, \n",
    "                                   random_state=1026, \n",
    "                                   min_samples_leaf=5,\n",
    "                                   min_samples_split = 5,\n",
    "                                   max_depth = 15,\n",
    "                                   n_jobs=-1, oob_score=True)\n",
    "modelfit(forest_reg, train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_feature_importance(forest_reg, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "RMSE :  1.4918\n",
      "CV Score : Mean -  6.0832 | Std -  1.2517 | Min -  4.7777 | Max - 8.0901\n",
      "Amount of time spent during training the model and cross validation: 0.942 seconds\n",
      "Wall time: 944 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=421, max_depth = 15, min_samples_split = 5)\n",
    "modelfit(tree_reg, train, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "RMSE :  0.3801\n",
      "CV Score : Mean -  3.9659 | Std -  0.5640 | Min -  3.2383 | Max - 4.7293\n",
      "Amount of time spent during training the model and cross validation: 119.693 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# tree_ada = DecisionTreeRegressor(random_state = 42,max_depth = 4)\n",
    "\n",
    "ada_reg = AdaBoostRegressor(\n",
    "    tree_reg, n_estimators=150, random_state=42,learning_rate=0.019, loss='square')\n",
    "modelfit(ada_reg, train, train_y)\n",
    "\n",
    "# 181.589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "RMSE :  6.3090\n",
      "CV Score : Mean -  12.8319 | Std -  2.8306 | Min -  9.8100 | Max - 16.9810\n",
      "Amount of time spent during training the model and cross validation: 385.655 seconds\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 100, 'max_depth': 14, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "\n",
    "params_1 = {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth' : 14,\n",
    "            'max_features': 'sqrt', 'min_samples_leaf': 15, 'min_samples_split': 5, \n",
    "            'loss': 'huber', 'random_state': 42}\n",
    "\n",
    "# train_dummies_prepared = num_pipeline.fit_transform(train_dummies)\n",
    "\n",
    "gdb_model = GradientBoostingRegressor(**params_1)\n",
    "modelfit(gdb_model, train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 regressors...\n",
      "Fitting regressor1: randomforestregressor (1/3)\n",
      "Fitting regressor2: decisiontreeregressor (2/3)\n",
      "Fitting regressor3: adaboostregressor (3/3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingRegressor(meta_regressor=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=15,\n",
       "                                                                                        min_samples_split=5,\n",
       "                                                                                        random_state=421),\n",
       "                                                   learning_rate=0.009,\n",
       "                                                   loss='square',\n",
       "                                                   n_estimators=300,\n",
       "                                                   random_state=42),\n",
       "                  regressors=[RandomForestRegressor(max_depth=15,\n",
       "                                                    min_samples_leaf=5,\n",
       "                                                    min_samples_split=5,\n",
       "                                                    n_estimators=300, n_jobs=-1,\n",
       "                                                    oob_score=True,\n",
       "                                                    random_state=1026),\n",
       "                              DecisionTreeRegressor(max_depth=15,\n",
       "                                                    min_samples_split=5,\n",
       "                                                    random_state=421),\n",
       "                              AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=15,\n",
       "                                                                                     min_samples_split=5,\n",
       "                                                                                     random_state=421),\n",
       "                                                learning_rate=0.009,\n",
       "                                                loss='square', n_estimators=300,\n",
       "                                                random_state=42)],\n",
       "                  verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stck_reg = StackingRegressor(\n",
    "    [forest_reg, tree_reg, ada_reg], \n",
    "    meta_regressor = ada_reg, \n",
    "     verbose=1)\n",
    "\n",
    "stck_reg.fit(train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.72873217522552"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "target = stck_reg.predict(valid)\n",
    "\n",
    "np.sqrt(mean_squared_error(target, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t the test set RMSE for         \n",
      " DecisionTreeRegressor(max_depth=15, min_samples_split=5, random_state=421) \n",
      " \t============================== \n",
      " 5.0024039450157884\n"
     ]
    }
   ],
   "source": [
    "# plot_feature_importance(ada_reg, train)\n",
    "# it seems head count and other unacceptable variables are determine it all ., \n",
    "# so its useless. \n",
    "\n",
    "def test_set_rmse(method):\n",
    "    target = method.predict(valid)\n",
    "    return print(\"\\t the test set RMSE for \\\n",
    "        \\n {} \\n \\t============================== \\n\".format(method),\\\n",
    "        np.sqrt(mean_squared_error(target, valid_y)))\n",
    "test_set_rmse(tree_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t the test set RMSE for         \n",
      " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=15,\n",
      "                                                       min_samples_split=5,\n",
      "                                                       random_state=421),\n",
      "                  learning_rate=0.009, loss='square', n_estimators=150,\n",
      "                  random_state=42) \n",
      " \t============================== \n",
      " 3.604858128066888\n"
     ]
    }
   ],
   "source": [
    "test_set_rmse(ada_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.251478370175772"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "target = forest_reg.predict(valid)\n",
    "\n",
    "np.sqrt(mean_squared_error(target, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA \\ PCA \\  KPCA: \n",
    "> the feature extraction tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import iris_data\n",
    "from mlxtend.preprocessing import standardize\n",
    "from mlxtend.feature_extraction import LinearDiscriminantAnalysis, PrincipalComponentAnalysis, RBFKernelPCA \n",
    "\n",
    "X, y = iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mlxtend.data import iris_data\n",
    "from mlxtend.preprocessing import standardize\n",
    "from mlxtend.feature_extraction import PrincipalComponentAnalysis\n",
    "\n",
    "X, y = iris_data()\n",
    "X = standardize(X)\n",
    "\n",
    "# PCA\n",
    "pca = PrincipalComponentAnalysis(n_components=3)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "# KPCA\n",
    "kpca = RBFKernelPCA(gamma=15.0, n_components=3)\n",
    "kpca.fit(X)\n",
    "X_kpca = kpca.X_projected_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "RMSE :  0.1155\n",
      "CV Score : Mean -  0.1667 | Std -  0.1374 | Min -  0.0000 | Max - 0.4000\n",
      "Amount of time spent during training the model and cross validation: 0.047 seconds\n",
      "\n",
      "Model Report\n",
      "RMSE :  0.1633\n",
      "CV Score : Mean -  0.1333 | Std -  0.1491 | Min -  0.0000 | Max - 0.4000\n",
      "Amount of time spent during training the model and cross validation: 0.044 seconds\n",
      "\n",
      "Model Report\n",
      "RMSE :  0.8042\n",
      "CV Score : Mean -  0.8121 | Std -  0.1432 | Min -  0.6325 | Max - 1.0000\n",
      "Amount of time spent during training the model and cross validation: 0.053 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "svc = SVC(len(np.unique(y)) + 1)\n",
    "modelfit(svc, X, y)\n",
    "modelfit(svc, X_pca, y)\n",
    "modelfit(svc, X_kpca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "RMSE :  0.2309\n",
      "CV Score : Mean -  0.1621 | Std -  0.1836 | Min -  0.0000 | Max - 0.4899\n",
      "Amount of time spent during training the model and cross validation: 0.047 seconds\n",
      "\n",
      "Model Report\n",
      "RMSE :  0.2309\n",
      "CV Score : Mean -  0.1955 | Std -  0.1687 | Min -  0.0000 | Max - 0.4899\n",
      "Amount of time spent during training the model and cross validation: 0.046 seconds\n",
      "\n",
      "Model Report\n",
      "RMSE :  0.7211\n",
      "CV Score : Mean -  0.8607 | Std -  0.1386 | Min -  0.7211 | Max - 1.0954\n",
      "Amount of time spent during training the model and cross validation: 0.032 seconds\n"
     ]
    }
   ],
   "source": [
    "svc2 = LinearSVC()\n",
    "modelfit(svc2, X, y)\n",
    "modelfit(svc2, X_pca, y)\n",
    "modelfit(svc2, X_kpca, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFS \\ SFS\n",
    "> feture selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.032057</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.337848</td>\n",
       "      <td>-1.398138</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-1.284407</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>1.263460</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.038005</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>0.819624</td>\n",
       "      <td>1.447956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>-1.281972</td>\n",
       "      <td>0.705893</td>\n",
       "      <td>0.922064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.795669</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>0.819624</td>\n",
       "      <td>1.053537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.432165</td>\n",
       "      <td>0.800654</td>\n",
       "      <td>0.933356</td>\n",
       "      <td>1.447956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.068662</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>0.762759</td>\n",
       "      <td>0.790591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0   -0.900681  1.032057 -1.341272 -1.312977\n",
       "1   -1.143017 -0.124958 -1.341272 -1.312977\n",
       "2   -1.385353  0.337848 -1.398138 -1.312977\n",
       "3   -1.506521  0.106445 -1.284407 -1.312977\n",
       "4   -1.021849  1.263460 -1.341272 -1.312977\n",
       "..        ...       ...       ...       ...\n",
       "145  1.038005 -0.124958  0.819624  1.447956\n",
       "146  0.553333 -1.281972  0.705893  0.922064\n",
       "147  0.795669 -0.124958  0.819624  1.053537\n",
       "148  0.432165  0.800654  0.933356  1.447956\n",
       "149  0.068662 -0.124958  0.762759  0.790591\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy score: 0.97\n",
      "Best subset (indices): (2, 3)\n",
      "Best subset (corresponding names): ('2', '3')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    " \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "efs1 = EFS(knn, \n",
    "           min_features=1,\n",
    "           max_features=4,\n",
    "           scoring='accuracy',\n",
    "           print_progress=True,\n",
    "           cv=5)\n",
    "\n",
    "efs1 = efs1.fit(X, y)\n",
    "\n",
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy score: 0.99\n",
      "Best subset (indices): (0, 1, 2, 3)\n",
      "Best subset (corresponding names): ('0', '1', '2', '3')\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(len(np.unique(y)) + 1)\n",
    "efs2 = EFS(svc, \n",
    "           min_features=1,\n",
    "           max_features=4,\n",
    "           scoring='accuracy',\n",
    "           print_progress=True,\n",
    "           cv=5)\n",
    "\n",
    "efs2 = efs2.fit(X, y)\n",
    "\n",
    "print('Best accuracy score: %.2f' % efs2.best_score_)\n",
    "print('Best subset (indices):', efs2.best_idx_)\n",
    "print('Best subset (corresponding names):', efs2.best_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'feature_idx': (3,),\n",
       "  'cv_scores': array([0.96]),\n",
       "  'avg_score': 0.96,\n",
       "  'feature_names': ('3',)},\n",
       " 2: {'feature_idx': (0, 3),\n",
       "  'cv_scores': array([0.96666667]),\n",
       "  'avg_score': 0.9666666666666667,\n",
       "  'feature_names': ('0', '3')},\n",
       " 3: {'feature_idx': (0, 2, 3),\n",
       "  'cv_scores': array([0.96]),\n",
       "  'avg_score': 0.96,\n",
       "  'feature_names': ('0', '2', '3')},\n",
       " 4: {'feature_idx': (0, 1, 2, 3),\n",
       "  'cv_scores': array([0.96666667]),\n",
       "  'avg_score': 0.9666666666666667,\n",
       "  'feature_names': ('0', '1', '2', '3')}}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs1 = SFS(knn, \n",
    "           k_features= X.shape[1], \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=0,\n",
    "           scoring='accuracy',\n",
    "           cv=0)\n",
    "\n",
    "sfs1 = sfs1.fit(X, y)\n",
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'feature_idx': (3,),\n",
       "  'cv_scores': array([0.96]),\n",
       "  'avg_score': 0.96,\n",
       "  'feature_names': ('3',)},\n",
       " 2: {'feature_idx': (0, 3),\n",
       "  'cv_scores': array([0.96666667]),\n",
       "  'avg_score': 0.9666666666666667,\n",
       "  'feature_names': ('0', '3')},\n",
       " 3: {'feature_idx': (0, 1, 3),\n",
       "  'cv_scores': array([0.96666667]),\n",
       "  'avg_score': 0.9666666666666667,\n",
       "  'feature_names': ('0', '1', '3')},\n",
       " 4: {'feature_idx': (0, 1, 2, 3),\n",
       "  'cv_scores': array([0.98666667]),\n",
       "  'avg_score': 0.9866666666666667,\n",
       "  'feature_names': ('0', '1', '2', '3')}}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sfs1 = SFS(svc, \n",
    "           k_features= X.shape[1], \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=0,\n",
    "           scoring='accuracy',\n",
    "           cv=0)\n",
    "\n",
    "sfs1 = sfs1.fit(X, y)\n",
    "sfs1.subsets_"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47b50d2908d96196e4220cfb4e81faa93803065ea975497e7026f672c1f58470"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('siming': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
